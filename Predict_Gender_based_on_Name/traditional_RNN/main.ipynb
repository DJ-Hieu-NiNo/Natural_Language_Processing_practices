{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wx3G_MFAE3P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0bd68bc-8a5e-44e4-dcd9-7c57378e60d0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygEgkweZAOK0",
        "colab_type": "text"
      },
      "source": [
        "# **Read Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoWIpPIQAM74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c94dee1b-432b-4d75-95df-78f7ac50b7da"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset=pd.read_csv(\"/content/gdrive/My Drive/RNN_name_gender/name_gender.csv\")\n",
        "data=dataset.values\n",
        "\n",
        "n_samples=data.shape[0]-1 #delete the last row, because it will not help.\n",
        "used_data=data[:n_samples,:2] \n",
        "print(\"Used data has shape : \",used_data.shape)\n",
        "print(\"Let's show some samples : \\n\",used_data[:5])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Used data has shape :  (95025, 2)\n",
            "Let's show some samples : \n",
            " [['Aaban' 'M']\n",
            " ['Aabha' 'F']\n",
            " ['Aabid' 'M']\n",
            " ['Aabriella' 'F']\n",
            " ['Aada' 'F']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQua60YtM2lr",
        "colab_type": "text"
      },
      "source": [
        "# **Label from 'M'/'F' to 0 / 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP7rhzu6NDJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1fd55f74-cfb4-427b-a8ec-e7288ea5d15d"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "m_idx=np.where(used_data[:,1]=='M')\n",
        "f_idx=np.where(used_data[:,1]=='F')\n",
        "used_data[m_idx,1]=0\n",
        "used_data[f_idx,1]=1\n",
        "print(\"Let's look some samples after converting gender labels : \",used_data[:5])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's look some samples after converting gender labels :  [['Aaban' 0]\n",
            " ['Aabha' 1]\n",
            " ['Aabid' 0]\n",
            " ['Aabriella' 1]\n",
            " ['Aada' 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94k6OuvRBJNx",
        "colab_type": "text"
      },
      "source": [
        "# **Define dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4NtML-rAe42",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9b37db0b-bb26-4ac6-85eb-d1d761cdbbb9"
      },
      "source": [
        "import string\n",
        "\n",
        "all_letters=string.ascii_letters # a,b,c,d.....z,A,B,C,D,...,Z\n",
        "dictionary=all_letters[:26] # only need lowercase letter\n",
        "print(\"Dictionary : \",dictionary)\n",
        "print(\"Length of dictionary : \",len(dictionary))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dictionary :  abcdefghijklmnopqrstuvwxyz\n",
            "Length of dictionary :  26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkIOuBz5C9yU",
        "colab_type": "text"
      },
      "source": [
        "# **Convert name to torch tensor with one-hot encoding method**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iS52PWLCoTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a900fe62-b13f-480b-a515-074e95f7c677"
      },
      "source": [
        "import torch\n",
        "\n",
        "n_letters=len(dictionary) #length of dict =26\n",
        "\n",
        "def name_to_tensor(name):\n",
        "  name=name.lower()\n",
        "  tensor=torch.zeros(len(name),1,n_letters) #each letter is an one-hot vector\n",
        "  for idx,letter in enumerate(name):\n",
        "    letter_idx=dictionary.find(letter)\n",
        "    tensor[idx][0][letter_idx]=1\n",
        "  return tensor\n",
        "\n",
        "#test an example\n",
        "print(\"Tensor for name : 'Hieu' : \\n\",name_to_tensor(\"Hieu\"))\n",
        "print(name_to_tensor(\"Hieu\").shape,\"\\n\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor for name : 'Hieu' : \n",
            " tensor([[[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 1., 0., 0., 0., 0., 0.]]])\n",
            "torch.Size([4, 1, 26]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHi1cLS5GajJ",
        "colab_type": "text"
      },
      "source": [
        "# **Split Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPSAtc4vGZ6x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a0643844-e47b-4c83-eb86-c56f095ad9a1"
      },
      "source": [
        "#split\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "n_samples=len(used_data)\n",
        "idx_range=np.arange(n_samples) # Get the index from 0 to 95024 \n",
        "#np.random.shuflle(idx_range) #shuffle index\n",
        "\n",
        "X_train,X_test_val,y_train,y_test_val=train_test_split(used_data[:,0],used_data[:,1],test_size=0.2) \n",
        "X_val,X_test,y_val,y_test=train_test_split(X_test_val,y_test_val,test_size=0.5)\n",
        "\n",
        "print(\"Shape of X_train , y_train : \",X_train.shape,y_train.shape)\n",
        "print(\"Shape of X_val, y_val : \",X_val.shape,y_val.shape)\n",
        "print(\"Shape of X_test, y_test : \",X_test.shape, y_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_train , y_train :  (76020,) (76020,)\n",
            "Shape of X_val, y_val :  (9502,) (9502,)\n",
            "Shape of X_test, y_test :  (9503,) (9503,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "266F5PF6Khnh",
        "colab_type": "text"
      },
      "source": [
        "# **Function to load data while training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3uVICaYEHKn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "60ff5b56-9b70-4372-9cd5-5e8a4ec2045f"
      },
      "source": [
        "from torch.autograd import Variable \n",
        "\n",
        "def get_data_pair(X,y,idx):\n",
        "  X_=Variable(name_to_tensor(X[idx]))\n",
        "  y_=Variable(torch.tensor([y[idx]]).long())\n",
        "  return X_,y_\n",
        "\n",
        "#test an example : \n",
        "print(X_train[100],y_train[100])\n",
        "print(\"shape X_train_tensor at 100 : \",get_data_pair(X_train,y_train,100)[0].shape)\n",
        "print(\"y_train_tensor at 100 : \",get_data_pair(X_train,y_train,100)[1].shape) \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sausha 1\n",
            "shape X_train_tensor at 100 :  torch.Size([6, 1, 26])\n",
            "y_train_tensor at 100 :  torch.Size([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx2BsIk0YHZd",
        "colab_type": "text"
      },
      "source": [
        "# **Define Model and send it to gpu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1ZPobuVOiyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Variable \n",
        "\n",
        "class RNN(nn.Module):\n",
        "\n",
        "  def __init__(self,input_size,hidden_size,output_size):\n",
        "    super(RNN,self).__init__()\n",
        "    self.input_size=input_size\n",
        "    self.hidden_size=hidden_size\n",
        "    self.output_size=output_size\n",
        "\n",
        "    self.i2h=nn.Linear(input_size+hidden_size,hidden_size)\n",
        "    self.i2o=nn.Linear(input_size+hidden_size,output_size)\n",
        "\n",
        "    self.softmax=nn.LogSoftmax()\n",
        "\n",
        "  def forward(self,input,hidden):\n",
        "    combined=torch.cat((input,hidden),1)\n",
        "    new_hidden=self.i2h(combined)\n",
        "    output=self.i2o(combined)\n",
        "    output=nn.LeakyReLU(0.02)(output)\n",
        "    output=self.softmax(output)\n",
        "    return output,new_hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return Variable(torch.zeros(1,self.hidden_size))\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "n_hiddens=64\n",
        "n_classes=2\n",
        "rnn=RNN(n_letters,n_hiddens,2).to(device) # input_size=26 , n_hidden =128 , output_size=\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_2ySfC-YXCg",
        "colab_type": "text"
      },
      "source": [
        "# **Define loss and  optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHMGXLbxYP94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion=nn.NLLLoss()\n",
        "learning_rate=0.0005\n",
        "optimizer=torch.optim.SGD(rnn.parameters(),lr=learning_rate)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1XbujkqYmVw",
        "colab_type": "text"
      },
      "source": [
        "# **Define train function for each name**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTAUWBEIYhvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(name_tensor,class_tensor,device):\n",
        "  rnn.zero_grad()\n",
        "  hidden=rnn.init_hidden()\n",
        "  hidden=hidden.to(device)\n",
        "\n",
        "  for i in range(name_tensor.size()[0]):\n",
        "    output,hidden=rnn(name_tensor[i],hidden)\n",
        "  \n",
        "  loss=criterion(output,class_tensor)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return output,loss.item()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAvPQ9kGaeYv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R_iuyLTY3KQ",
        "colab_type": "text"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmNEAURIY2av",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "641520b2-6309-467f-85e6-8cf42e3669f2"
      },
      "source": [
        "epochs = 10\n",
        "print_steps=1000\n",
        "print_all_steps=25000\n",
        "indices_train=np.arange(len(X_train))\n",
        "train_loss_list=[]\n",
        "train_acc_list=[]\n",
        "val_loss_list=[]\n",
        "val_acc_list=[]\n",
        "\n",
        "def evaluate(X,y,device):\n",
        "  loss=0\n",
        "  correct=0\n",
        "  for i in range(len(X)):\n",
        "    name_tensor,class_tensor=get_data_pair(X,y,i)\n",
        "    name_tensor=name_tensor.to(device)\n",
        "    class_tensor=class_tensor.to(device)\n",
        "    hidden=rnn.init_hidden().to(device)\n",
        "    for j in range(name_tensor.size()[0]):\n",
        "      predicted,hidden=rnn(name_tensor[j],hidden)\n",
        "    loss+=criterion(predicted,class_tensor)\n",
        "    idx_predicted=torch.max(predicted.data,1)[1]\n",
        "    correct+=(idx_predicted==class_tensor).sum()\n",
        "  return loss/len(X),correct.item()/len(X)*100\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss=0\n",
        "  np.random.shuffle(indices_train)\n",
        "  for i,idx in enumerate(indices_train):\n",
        "    name_tensor,class_tensor=get_data_pair(X_train,y_train,idx)\n",
        "    name_tensor=name_tensor.to(device)\n",
        "    class_tensor=class_tensor.to(device)\n",
        "    output,loss=train(name_tensor,class_tensor,device)\n",
        "    train_loss+=loss\n",
        "    if(i%print_steps==0 and i>0 and i%print_all_steps !=0):\n",
        "      print(\"Iter :\",i,\"at epoch: \",epoch+1,\"/ \",epochs,\" Train Loss : \",train_loss/print_steps)\n",
        "      train_loss=0\n",
        "    elif(i%print_all_steps==0 and i>0):\n",
        "      with torch.no_grad():\n",
        "\n",
        "        train_acc=evaluate(X_train,y_train,device)[1] #Calculate acc for all\n",
        "        train_acc_list.append(train_acc)\n",
        "        train_loss_list.append(train_loss/print_steps) #calculate loss after \"print_steps\" training samples and get mean\n",
        "        \n",
        "        val_loss,val_acc=evaluate(X_val,y_val,device)\n",
        "        val_loss_list.append(val_loss)\n",
        "        val_acc_list.append(val_acc)\n",
        "        print(\"Iter: \",i,\"at epoch: \",epoch+1,\"/\",epochs,\" train loss :\",train_loss/print_steps,\"Train acc: \",train_acc,\" val loss: \",val_loss,\" val acc: \",val_acc)\n",
        "        train_loss=0"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter : 1000 at epoch:  1 /  10  Train Loss :  0.6938831470012665\n",
            "Iter : 2000 at epoch:  1 /  10  Train Loss :  0.6931130584478379\n",
            "Iter : 3000 at epoch:  1 /  10  Train Loss :  0.6932850676774979\n",
            "Iter : 4000 at epoch:  1 /  10  Train Loss :  0.6930759158134461\n",
            "Iter : 5000 at epoch:  1 /  10  Train Loss :  0.6926899731159211\n",
            "Iter : 6000 at epoch:  1 /  10  Train Loss :  0.6929932457208633\n",
            "Iter : 7000 at epoch:  1 /  10  Train Loss :  0.6931685853600502\n",
            "Iter : 8000 at epoch:  1 /  10  Train Loss :  0.6927827689647674\n",
            "Iter : 9000 at epoch:  1 /  10  Train Loss :  0.6923655796051026\n",
            "Iter : 10000 at epoch:  1 /  10  Train Loss :  0.6923891479969024\n",
            "Iter : 11000 at epoch:  1 /  10  Train Loss :  0.6923407233357429\n",
            "Iter : 12000 at epoch:  1 /  10  Train Loss :  0.6916946773529052\n",
            "Iter : 13000 at epoch:  1 /  10  Train Loss :  0.6920001274347305\n",
            "Iter : 14000 at epoch:  1 /  10  Train Loss :  0.6920231842398643\n",
            "Iter : 15000 at epoch:  1 /  10  Train Loss :  0.6903069588541985\n",
            "Iter : 16000 at epoch:  1 /  10  Train Loss :  0.6913735882043839\n",
            "Iter : 17000 at epoch:  1 /  10  Train Loss :  0.6907939492464066\n",
            "Iter : 18000 at epoch:  1 /  10  Train Loss :  0.6908727324008942\n",
            "Iter : 19000 at epoch:  1 /  10  Train Loss :  0.6912129235267639\n",
            "Iter : 20000 at epoch:  1 /  10  Train Loss :  0.6907333930134774\n",
            "Iter : 21000 at epoch:  1 /  10  Train Loss :  0.6877181922197342\n",
            "Iter : 22000 at epoch:  1 /  10  Train Loss :  0.688869978427887\n",
            "Iter : 23000 at epoch:  1 /  10  Train Loss :  0.6881675400137901\n",
            "Iter : 24000 at epoch:  1 /  10  Train Loss :  0.6898895789384842\n",
            "Iter:  25000 at epoch:  1 / 10  train loss : 0.688013046503067 Train acc:  52.141541699552754  val loss:  tensor(0.6874)  val acc:  52.94674805304147\n",
            "Iter : 26000 at epoch:  1 /  10  Train Loss :  0.6875343594551087\n",
            "Iter : 27000 at epoch:  1 /  10  Train Loss :  0.6859699254631996\n",
            "Iter : 28000 at epoch:  1 /  10  Train Loss :  0.6860607196688652\n",
            "Iter : 29000 at epoch:  1 /  10  Train Loss :  0.6790904536247253\n",
            "Iter : 30000 at epoch:  1 /  10  Train Loss :  0.6543984795212746\n",
            "Iter : 31000 at epoch:  1 /  10  Train Loss :  0.6369551689624786\n",
            "Iter : 32000 at epoch:  1 /  10  Train Loss :  0.6306156782209873\n",
            "Iter : 33000 at epoch:  1 /  10  Train Loss :  0.611599212706089\n",
            "Iter : 34000 at epoch:  1 /  10  Train Loss :  0.6106340527534485\n",
            "Iter : 35000 at epoch:  1 /  10  Train Loss :  0.5849255965054035\n",
            "Iter : 36000 at epoch:  1 /  10  Train Loss :  0.5838979454934597\n",
            "Iter : 37000 at epoch:  1 /  10  Train Loss :  0.5704732244610786\n",
            "Iter : 38000 at epoch:  1 /  10  Train Loss :  0.5695843275487423\n",
            "Iter : 39000 at epoch:  1 /  10  Train Loss :  0.56728076004982\n",
            "Iter : 40000 at epoch:  1 /  10  Train Loss :  0.5635471991300582\n",
            "Iter : 41000 at epoch:  1 /  10  Train Loss :  0.5626557013094425\n",
            "Iter : 42000 at epoch:  1 /  10  Train Loss :  0.5565256702452898\n",
            "Iter : 43000 at epoch:  1 /  10  Train Loss :  0.5444831003844738\n",
            "Iter : 44000 at epoch:  1 /  10  Train Loss :  0.5379573603719473\n",
            "Iter : 45000 at epoch:  1 /  10  Train Loss :  0.5376271513104439\n",
            "Iter : 46000 at epoch:  1 /  10  Train Loss :  0.5089439195394516\n",
            "Iter : 47000 at epoch:  1 /  10  Train Loss :  0.525265211686492\n",
            "Iter : 48000 at epoch:  1 /  10  Train Loss :  0.5153803622126579\n",
            "Iter : 49000 at epoch:  1 /  10  Train Loss :  0.5212247769981623\n",
            "Iter:  50000 at epoch:  1 / 10  train loss : 0.5052151473909616 Train acc:  77.51118126808734  val loss:  tensor(0.5127)  val acc:  77.60471479688486\n",
            "Iter : 51000 at epoch:  1 /  10  Train Loss :  0.5021778487414121\n",
            "Iter : 52000 at epoch:  1 /  10  Train Loss :  0.5014774850606918\n",
            "Iter : 53000 at epoch:  1 /  10  Train Loss :  0.49318730491399765\n",
            "Iter : 54000 at epoch:  1 /  10  Train Loss :  0.5005139092504978\n",
            "Iter : 55000 at epoch:  1 /  10  Train Loss :  0.5083798033595085\n",
            "Iter : 56000 at epoch:  1 /  10  Train Loss :  0.48439319636672734\n",
            "Iter : 57000 at epoch:  1 /  10  Train Loss :  0.4904464971423149\n",
            "Iter : 58000 at epoch:  1 /  10  Train Loss :  0.48227199011296035\n",
            "Iter : 59000 at epoch:  1 /  10  Train Loss :  0.4719827966839075\n",
            "Iter : 60000 at epoch:  1 /  10  Train Loss :  0.4831282996609807\n",
            "Iter : 61000 at epoch:  1 /  10  Train Loss :  0.4996154144108295\n",
            "Iter : 62000 at epoch:  1 /  10  Train Loss :  0.4816029041856527\n",
            "Iter : 63000 at epoch:  1 /  10  Train Loss :  0.47244579791277647\n",
            "Iter : 64000 at epoch:  1 /  10  Train Loss :  0.47678435944765807\n",
            "Iter : 65000 at epoch:  1 /  10  Train Loss :  0.46637077049911024\n",
            "Iter : 66000 at epoch:  1 /  10  Train Loss :  0.481122334562242\n",
            "Iter : 67000 at epoch:  1 /  10  Train Loss :  0.4788230795562267\n",
            "Iter : 68000 at epoch:  1 /  10  Train Loss :  0.4740007617250085\n",
            "Iter : 69000 at epoch:  1 /  10  Train Loss :  0.471143381126225\n",
            "Iter : 70000 at epoch:  1 /  10  Train Loss :  0.4577759057730436\n",
            "Iter : 71000 at epoch:  1 /  10  Train Loss :  0.4589561364836991\n",
            "Iter : 72000 at epoch:  1 /  10  Train Loss :  0.460763072066009\n",
            "Iter : 73000 at epoch:  1 /  10  Train Loss :  0.45900741999968886\n",
            "Iter : 74000 at epoch:  1 /  10  Train Loss :  0.45911379680782555\n",
            "Iter:  75000 at epoch:  1 / 10  train loss : 0.458255045928061 Train acc:  80.37884767166535  val loss:  tensor(0.4519)  val acc:  80.83561355504104\n",
            "Iter : 76000 at epoch:  1 /  10  Train Loss :  0.46002448875829577\n",
            "Iter : 1000 at epoch:  2 /  10  Train Loss :  0.4363856363482773\n",
            "Iter : 2000 at epoch:  2 /  10  Train Loss :  0.4400932065658271\n",
            "Iter : 3000 at epoch:  2 /  10  Train Loss :  0.46330513382330535\n",
            "Iter : 4000 at epoch:  2 /  10  Train Loss :  0.4591168260537088\n",
            "Iter : 5000 at epoch:  2 /  10  Train Loss :  0.4391262862496078\n",
            "Iter : 6000 at epoch:  2 /  10  Train Loss :  0.4234408364631236\n",
            "Iter : 7000 at epoch:  2 /  10  Train Loss :  0.4292187227755785\n",
            "Iter : 8000 at epoch:  2 /  10  Train Loss :  0.44616483528353273\n",
            "Iter : 9000 at epoch:  2 /  10  Train Loss :  0.43561133519560097\n",
            "Iter : 10000 at epoch:  2 /  10  Train Loss :  0.4414031806178391\n",
            "Iter : 11000 at epoch:  2 /  10  Train Loss :  0.4340401322171092\n",
            "Iter : 12000 at epoch:  2 /  10  Train Loss :  0.44339919639751313\n",
            "Iter : 13000 at epoch:  2 /  10  Train Loss :  0.4225489804465324\n",
            "Iter : 14000 at epoch:  2 /  10  Train Loss :  0.44189834328740835\n",
            "Iter : 15000 at epoch:  2 /  10  Train Loss :  0.44534050339087844\n",
            "Iter : 16000 at epoch:  2 /  10  Train Loss :  0.42644147339463234\n",
            "Iter : 17000 at epoch:  2 /  10  Train Loss :  0.4480750148575753\n",
            "Iter : 18000 at epoch:  2 /  10  Train Loss :  0.41116859318315985\n",
            "Iter : 19000 at epoch:  2 /  10  Train Loss :  0.43232360512390733\n",
            "Iter : 20000 at epoch:  2 /  10  Train Loss :  0.4174752744976431\n",
            "Iter : 21000 at epoch:  2 /  10  Train Loss :  0.41704958068951964\n",
            "Iter : 22000 at epoch:  2 /  10  Train Loss :  0.4307455937117338\n",
            "Iter : 23000 at epoch:  2 /  10  Train Loss :  0.42564580629765986\n",
            "Iter : 24000 at epoch:  2 /  10  Train Loss :  0.4091711374660954\n",
            "Iter:  25000 at epoch:  2 / 10  train loss : 0.4184860056284815 Train acc:  81.03262299394896  val loss:  tensor(0.4194)  val acc:  81.64596926962744\n",
            "Iter : 26000 at epoch:  2 /  10  Train Loss :  0.4307196238040924\n",
            "Iter : 27000 at epoch:  2 /  10  Train Loss :  0.4241481996942312\n",
            "Iter : 28000 at epoch:  2 /  10  Train Loss :  0.4173808456584811\n",
            "Iter : 29000 at epoch:  2 /  10  Train Loss :  0.4202052124608308\n",
            "Iter : 30000 at epoch:  2 /  10  Train Loss :  0.4031353263799101\n",
            "Iter : 31000 at epoch:  2 /  10  Train Loss :  0.40307410573773084\n",
            "Iter : 32000 at epoch:  2 /  10  Train Loss :  0.42656816318817437\n",
            "Iter : 33000 at epoch:  2 /  10  Train Loss :  0.4274948153188452\n",
            "Iter : 34000 at epoch:  2 /  10  Train Loss :  0.4077209866056219\n",
            "Iter : 35000 at epoch:  2 /  10  Train Loss :  0.40701448904909193\n",
            "Iter : 36000 at epoch:  2 /  10  Train Loss :  0.43013256426155566\n",
            "Iter : 37000 at epoch:  2 /  10  Train Loss :  0.41297565896622834\n",
            "Iter : 38000 at epoch:  2 /  10  Train Loss :  0.424398148637265\n",
            "Iter : 39000 at epoch:  2 /  10  Train Loss :  0.4271960267359391\n",
            "Iter : 40000 at epoch:  2 /  10  Train Loss :  0.41442513251677154\n",
            "Iter : 41000 at epoch:  2 /  10  Train Loss :  0.39125423893891276\n",
            "Iter : 42000 at epoch:  2 /  10  Train Loss :  0.4098997758030891\n",
            "Iter : 43000 at epoch:  2 /  10  Train Loss :  0.42029013108462093\n",
            "Iter : 44000 at epoch:  2 /  10  Train Loss :  0.41368391758482903\n",
            "Iter : 45000 at epoch:  2 /  10  Train Loss :  0.45815579300373793\n",
            "Iter : 46000 at epoch:  2 /  10  Train Loss :  0.39837676952034234\n",
            "Iter : 47000 at epoch:  2 /  10  Train Loss :  0.4315052554840222\n",
            "Iter : 48000 at epoch:  2 /  10  Train Loss :  0.40509801601246\n",
            "Iter : 49000 at epoch:  2 /  10  Train Loss :  0.41297537095472214\n",
            "Iter:  50000 at epoch:  2 / 10  train loss : 0.39146228139102457 Train acc:  81.29965798474086  val loss:  tensor(0.4074)  val acc:  81.86697537360556\n",
            "Iter : 51000 at epoch:  2 /  10  Train Loss :  0.40763784113153817\n",
            "Iter : 52000 at epoch:  2 /  10  Train Loss :  0.40176776178739965\n",
            "Iter : 53000 at epoch:  2 /  10  Train Loss :  0.4112043079137802\n",
            "Iter : 54000 at epoch:  2 /  10  Train Loss :  0.38422472098749133\n",
            "Iter : 55000 at epoch:  2 /  10  Train Loss :  0.42570780813414605\n",
            "Iter : 56000 at epoch:  2 /  10  Train Loss :  0.4040608187736943\n",
            "Iter : 57000 at epoch:  2 /  10  Train Loss :  0.4070838792892173\n",
            "Iter : 58000 at epoch:  2 /  10  Train Loss :  0.4120750484922901\n",
            "Iter : 59000 at epoch:  2 /  10  Train Loss :  0.4371120525943115\n",
            "Iter : 60000 at epoch:  2 /  10  Train Loss :  0.4038718854952604\n",
            "Iter : 61000 at epoch:  2 /  10  Train Loss :  0.41339206970017406\n",
            "Iter : 62000 at epoch:  2 /  10  Train Loss :  0.3786337936595082\n",
            "Iter : 63000 at epoch:  2 /  10  Train Loss :  0.41578870052471756\n",
            "Iter : 64000 at epoch:  2 /  10  Train Loss :  0.4062831272641197\n",
            "Iter : 65000 at epoch:  2 /  10  Train Loss :  0.41079564297478643\n",
            "Iter : 66000 at epoch:  2 /  10  Train Loss :  0.4200452754572034\n",
            "Iter : 67000 at epoch:  2 /  10  Train Loss :  0.3958434791034088\n",
            "Iter : 68000 at epoch:  2 /  10  Train Loss :  0.4197470369990915\n",
            "Iter : 69000 at epoch:  2 /  10  Train Loss :  0.43621076972503214\n",
            "Iter : 70000 at epoch:  2 /  10  Train Loss :  0.4153172141285613\n",
            "Iter : 71000 at epoch:  2 /  10  Train Loss :  0.4145066945971921\n",
            "Iter : 72000 at epoch:  2 /  10  Train Loss :  0.4206414971956983\n",
            "Iter : 73000 at epoch:  2 /  10  Train Loss :  0.39293382712919267\n",
            "Iter : 74000 at epoch:  2 /  10  Train Loss :  0.418915689419955\n",
            "Iter:  75000 at epoch:  2 / 10  train loss : 0.4060444967062212 Train acc:  81.38516179952644  val loss:  tensor(0.4012)  val acc:  81.87749947379498\n",
            "Iter : 76000 at epoch:  2 /  10  Train Loss :  0.4127730793459341\n",
            "Iter : 1000 at epoch:  3 /  10  Train Loss :  0.38521932949125764\n",
            "Iter : 2000 at epoch:  3 /  10  Train Loss :  0.3987588834408671\n",
            "Iter : 3000 at epoch:  3 /  10  Train Loss :  0.4244954667724669\n",
            "Iter : 4000 at epoch:  3 /  10  Train Loss :  0.37953645672183484\n",
            "Iter : 5000 at epoch:  3 /  10  Train Loss :  0.40449078538268807\n",
            "Iter : 6000 at epoch:  3 /  10  Train Loss :  0.39107468267576767\n",
            "Iter : 7000 at epoch:  3 /  10  Train Loss :  0.41748408002126963\n",
            "Iter : 8000 at epoch:  3 /  10  Train Loss :  0.40977747088857\n",
            "Iter : 9000 at epoch:  3 /  10  Train Loss :  0.41036001294804736\n",
            "Iter : 10000 at epoch:  3 /  10  Train Loss :  0.38569266071822494\n",
            "Iter : 11000 at epoch:  3 /  10  Train Loss :  0.4066797106387094\n",
            "Iter : 12000 at epoch:  3 /  10  Train Loss :  0.40667310494789854\n",
            "Iter : 13000 at epoch:  3 /  10  Train Loss :  0.40443693435471506\n",
            "Iter : 14000 at epoch:  3 /  10  Train Loss :  0.4028242900054902\n",
            "Iter : 15000 at epoch:  3 /  10  Train Loss :  0.3951543935649097\n",
            "Iter : 16000 at epoch:  3 /  10  Train Loss :  0.3891234483234584\n",
            "Iter : 17000 at epoch:  3 /  10  Train Loss :  0.42687724966835233\n",
            "Iter : 18000 at epoch:  3 /  10  Train Loss :  0.382850118085742\n",
            "Iter : 19000 at epoch:  3 /  10  Train Loss :  0.4167013239315711\n",
            "Iter : 20000 at epoch:  3 /  10  Train Loss :  0.4139686423242092\n",
            "Iter : 21000 at epoch:  3 /  10  Train Loss :  0.3804364621480927\n",
            "Iter : 22000 at epoch:  3 /  10  Train Loss :  0.40951329658925534\n",
            "Iter : 23000 at epoch:  3 /  10  Train Loss :  0.39163737029209733\n",
            "Iter : 24000 at epoch:  3 /  10  Train Loss :  0.3909913632958196\n",
            "Iter:  25000 at epoch:  3 / 10  train loss : 0.36029704747442154 Train acc:  81.97184951328597  val loss:  tensor(0.3994)  val acc:  82.0037886760682\n",
            "Iter : 26000 at epoch:  3 /  10  Train Loss :  0.40122192400414497\n",
            "Iter : 27000 at epoch:  3 /  10  Train Loss :  0.39877237215358763\n",
            "Iter : 28000 at epoch:  3 /  10  Train Loss :  0.42534071872150525\n",
            "Iter : 29000 at epoch:  3 /  10  Train Loss :  0.3822133807959035\n",
            "Iter : 30000 at epoch:  3 /  10  Train Loss :  0.41227908576419575\n",
            "Iter : 31000 at epoch:  3 /  10  Train Loss :  0.4001337052327581\n",
            "Iter : 32000 at epoch:  3 /  10  Train Loss :  0.38570840227045117\n",
            "Iter : 33000 at epoch:  3 /  10  Train Loss :  0.3745860292254947\n",
            "Iter : 34000 at epoch:  3 /  10  Train Loss :  0.4203911629873328\n",
            "Iter : 35000 at epoch:  3 /  10  Train Loss :  0.3956296071992256\n",
            "Iter : 36000 at epoch:  3 /  10  Train Loss :  0.4201518112141639\n",
            "Iter : 37000 at epoch:  3 /  10  Train Loss :  0.394776117740199\n",
            "Iter : 38000 at epoch:  3 /  10  Train Loss :  0.3920598865970969\n",
            "Iter : 39000 at epoch:  3 /  10  Train Loss :  0.37884303629305216\n",
            "Iter : 40000 at epoch:  3 /  10  Train Loss :  0.42869975440390407\n",
            "Iter : 41000 at epoch:  3 /  10  Train Loss :  0.4140956279328093\n",
            "Iter : 42000 at epoch:  3 /  10  Train Loss :  0.3947895593913272\n",
            "Iter : 43000 at epoch:  3 /  10  Train Loss :  0.4130202713916078\n",
            "Iter : 44000 at epoch:  3 /  10  Train Loss :  0.37316690491884946\n",
            "Iter : 45000 at epoch:  3 /  10  Train Loss :  0.38206061148550363\n",
            "Iter : 46000 at epoch:  3 /  10  Train Loss :  0.37359296340867876\n",
            "Iter : 47000 at epoch:  3 /  10  Train Loss :  0.3837287299791351\n",
            "Iter : 48000 at epoch:  3 /  10  Train Loss :  0.3908840377354063\n",
            "Iter : 49000 at epoch:  3 /  10  Train Loss :  0.3834569983058609\n",
            "Iter:  50000 at epoch:  3 / 10  train loss : 0.4053951234528795 Train acc:  82.2336227308603  val loss:  tensor(0.3918)  val acc:  82.34055988213008\n",
            "Iter : 51000 at epoch:  3 /  10  Train Loss :  0.38713444441743194\n",
            "Iter : 52000 at epoch:  3 /  10  Train Loss :  0.42455228996975347\n",
            "Iter : 53000 at epoch:  3 /  10  Train Loss :  0.40831294531188905\n",
            "Iter : 54000 at epoch:  3 /  10  Train Loss :  0.3805187948141247\n",
            "Iter : 55000 at epoch:  3 /  10  Train Loss :  0.3880260398387909\n",
            "Iter : 56000 at epoch:  3 /  10  Train Loss :  0.4056948759946972\n",
            "Iter : 57000 at epoch:  3 /  10  Train Loss :  0.3606245624860749\n",
            "Iter : 58000 at epoch:  3 /  10  Train Loss :  0.3943559893565252\n",
            "Iter : 59000 at epoch:  3 /  10  Train Loss :  0.3883158791037276\n",
            "Iter : 60000 at epoch:  3 /  10  Train Loss :  0.4186493135252968\n",
            "Iter : 61000 at epoch:  3 /  10  Train Loss :  0.3901646371250972\n",
            "Iter : 62000 at epoch:  3 /  10  Train Loss :  0.37777756081335245\n",
            "Iter : 63000 at epoch:  3 /  10  Train Loss :  0.39558453314146025\n",
            "Iter : 64000 at epoch:  3 /  10  Train Loss :  0.38627000152273105\n",
            "Iter : 65000 at epoch:  3 /  10  Train Loss :  0.3983508405671455\n",
            "Iter : 66000 at epoch:  3 /  10  Train Loss :  0.3730593977519311\n",
            "Iter : 67000 at epoch:  3 /  10  Train Loss :  0.4190006326250732\n",
            "Iter : 68000 at epoch:  3 /  10  Train Loss :  0.38580097096506505\n",
            "Iter : 69000 at epoch:  3 /  10  Train Loss :  0.376056450383272\n",
            "Iter : 70000 at epoch:  3 /  10  Train Loss :  0.3959238382955082\n",
            "Iter : 71000 at epoch:  3 /  10  Train Loss :  0.3891377834295854\n",
            "Iter : 72000 at epoch:  3 /  10  Train Loss :  0.3796579276942648\n",
            "Iter : 73000 at epoch:  3 /  10  Train Loss :  0.40444015101715924\n",
            "Iter : 74000 at epoch:  3 /  10  Train Loss :  0.414997859260533\n",
            "Iter:  75000 at epoch:  3 / 10  train loss : 0.3897647155309096 Train acc:  82.06129965798475  val loss:  tensor(0.3902)  val acc:  82.45632498421385\n",
            "Iter : 76000 at epoch:  3 /  10  Train Loss :  0.412962800309062\n",
            "Iter : 1000 at epoch:  4 /  10  Train Loss :  0.36255184186669065\n",
            "Iter : 2000 at epoch:  4 /  10  Train Loss :  0.3892030525971204\n",
            "Iter : 3000 at epoch:  4 /  10  Train Loss :  0.40449724107561635\n",
            "Iter : 4000 at epoch:  4 /  10  Train Loss :  0.39476879442622886\n",
            "Iter : 5000 at epoch:  4 /  10  Train Loss :  0.39994591974653304\n",
            "Iter : 6000 at epoch:  4 /  10  Train Loss :  0.4043517105556093\n",
            "Iter : 7000 at epoch:  4 /  10  Train Loss :  0.3806233493315522\n",
            "Iter : 8000 at epoch:  4 /  10  Train Loss :  0.379612122412771\n",
            "Iter : 9000 at epoch:  4 /  10  Train Loss :  0.3798488090555184\n",
            "Iter : 10000 at epoch:  4 /  10  Train Loss :  0.3774242725339718\n",
            "Iter : 11000 at epoch:  4 /  10  Train Loss :  0.38180016306741166\n",
            "Iter : 12000 at epoch:  4 /  10  Train Loss :  0.4091347319902852\n",
            "Iter : 13000 at epoch:  4 /  10  Train Loss :  0.3807884214175865\n",
            "Iter : 14000 at epoch:  4 /  10  Train Loss :  0.3965081047946587\n",
            "Iter : 15000 at epoch:  4 /  10  Train Loss :  0.3838655570973642\n",
            "Iter : 16000 at epoch:  4 /  10  Train Loss :  0.40048136298544706\n",
            "Iter : 17000 at epoch:  4 /  10  Train Loss :  0.3976723932530731\n",
            "Iter : 18000 at epoch:  4 /  10  Train Loss :  0.40797079165652395\n",
            "Iter : 19000 at epoch:  4 /  10  Train Loss :  0.40617677668249236\n",
            "Iter : 20000 at epoch:  4 /  10  Train Loss :  0.4057573793595657\n",
            "Iter : 21000 at epoch:  4 /  10  Train Loss :  0.42557704931590706\n",
            "Iter : 22000 at epoch:  4 /  10  Train Loss :  0.36126925599947574\n",
            "Iter : 23000 at epoch:  4 /  10  Train Loss :  0.39620905214687807\n",
            "Iter : 24000 at epoch:  4 /  10  Train Loss :  0.38483654961781577\n",
            "Iter:  25000 at epoch:  4 / 10  train loss : 0.41246531161665917 Train acc:  82.2533543804262  val loss:  tensor(0.3879)  val acc:  82.61418648705535\n",
            "Iter : 26000 at epoch:  4 /  10  Train Loss :  0.3741965708388016\n",
            "Iter : 27000 at epoch:  4 /  10  Train Loss :  0.41393487178720534\n",
            "Iter : 28000 at epoch:  4 /  10  Train Loss :  0.41405052412394433\n",
            "Iter : 29000 at epoch:  4 /  10  Train Loss :  0.4024895680951886\n",
            "Iter : 30000 at epoch:  4 /  10  Train Loss :  0.402026495018974\n",
            "Iter : 31000 at epoch:  4 /  10  Train Loss :  0.41753970526484774\n",
            "Iter : 32000 at epoch:  4 /  10  Train Loss :  0.3963563722595572\n",
            "Iter : 33000 at epoch:  4 /  10  Train Loss :  0.3661982310558669\n",
            "Iter : 34000 at epoch:  4 /  10  Train Loss :  0.3649879361637868\n",
            "Iter : 35000 at epoch:  4 /  10  Train Loss :  0.37472056748811156\n",
            "Iter : 36000 at epoch:  4 /  10  Train Loss :  0.36291166670946406\n",
            "Iter : 37000 at epoch:  4 /  10  Train Loss :  0.40020060700038446\n",
            "Iter : 38000 at epoch:  4 /  10  Train Loss :  0.40755435364926235\n",
            "Iter : 39000 at epoch:  4 /  10  Train Loss :  0.38811382338032124\n",
            "Iter : 40000 at epoch:  4 /  10  Train Loss :  0.357114346306771\n",
            "Iter : 41000 at epoch:  4 /  10  Train Loss :  0.39158909051865337\n",
            "Iter : 42000 at epoch:  4 /  10  Train Loss :  0.38379095431766475\n",
            "Iter : 43000 at epoch:  4 /  10  Train Loss :  0.3711337293172255\n",
            "Iter : 44000 at epoch:  4 /  10  Train Loss :  0.3824736365885474\n",
            "Iter : 45000 at epoch:  4 /  10  Train Loss :  0.3498306992854923\n",
            "Iter : 46000 at epoch:  4 /  10  Train Loss :  0.38543924582516775\n",
            "Iter : 47000 at epoch:  4 /  10  Train Loss :  0.4205903225163929\n",
            "Iter : 48000 at epoch:  4 /  10  Train Loss :  0.39642348401714117\n",
            "Iter : 49000 at epoch:  4 /  10  Train Loss :  0.38058418602123856\n",
            "Iter:  50000 at epoch:  4 / 10  train loss : 0.37521604481618853 Train acc:  82.63877926861353  val loss:  tensor(0.3871)  val acc:  82.62471058724479\n",
            "Iter : 51000 at epoch:  4 /  10  Train Loss :  0.3684828184926882\n",
            "Iter : 52000 at epoch:  4 /  10  Train Loss :  0.38798637441825123\n",
            "Iter : 53000 at epoch:  4 /  10  Train Loss :  0.37357734610605986\n",
            "Iter : 54000 at epoch:  4 /  10  Train Loss :  0.3864259253302589\n",
            "Iter : 55000 at epoch:  4 /  10  Train Loss :  0.4334394261897542\n",
            "Iter : 56000 at epoch:  4 /  10  Train Loss :  0.379401283592917\n",
            "Iter : 57000 at epoch:  4 /  10  Train Loss :  0.40521771448431537\n",
            "Iter : 58000 at epoch:  4 /  10  Train Loss :  0.3870182769712992\n",
            "Iter : 59000 at epoch:  4 /  10  Train Loss :  0.3854950332303997\n",
            "Iter : 60000 at epoch:  4 /  10  Train Loss :  0.39514801363670266\n",
            "Iter : 61000 at epoch:  4 /  10  Train Loss :  0.3795538945747539\n",
            "Iter : 62000 at epoch:  4 /  10  Train Loss :  0.4174836088134907\n",
            "Iter : 63000 at epoch:  4 /  10  Train Loss :  0.3749969419375993\n",
            "Iter : 64000 at epoch:  4 /  10  Train Loss :  0.3786730473302305\n",
            "Iter : 65000 at epoch:  4 /  10  Train Loss :  0.38593091246299444\n",
            "Iter : 66000 at epoch:  4 /  10  Train Loss :  0.34492382845981046\n",
            "Iter : 67000 at epoch:  4 /  10  Train Loss :  0.3872517413245514\n",
            "Iter : 68000 at epoch:  4 /  10  Train Loss :  0.39867715539364146\n",
            "Iter : 69000 at epoch:  4 /  10  Train Loss :  0.3726087908113841\n",
            "Iter : 70000 at epoch:  4 /  10  Train Loss :  0.4144292774894275\n",
            "Iter : 71000 at epoch:  4 /  10  Train Loss :  0.4038372378991917\n",
            "Iter : 72000 at epoch:  4 /  10  Train Loss :  0.3595981885236688\n",
            "Iter : 73000 at epoch:  4 /  10  Train Loss :  0.40710457948595286\n",
            "Iter : 74000 at epoch:  4 /  10  Train Loss :  0.40779016035608945\n",
            "Iter:  75000 at epoch:  4 / 10  train loss : 0.36374001849722115 Train acc:  82.47040252565114  val loss:  tensor(0.3840)  val acc:  82.64575878762366\n",
            "Iter : 76000 at epoch:  4 /  10  Train Loss :  0.3774862705180421\n",
            "Iter : 1000 at epoch:  5 /  10  Train Loss :  0.3815617995932698\n",
            "Iter : 2000 at epoch:  5 /  10  Train Loss :  0.3864686023420654\n",
            "Iter : 3000 at epoch:  5 /  10  Train Loss :  0.37677510946057735\n",
            "Iter : 4000 at epoch:  5 /  10  Train Loss :  0.3569651084551588\n",
            "Iter : 5000 at epoch:  5 /  10  Train Loss :  0.39228836487256924\n",
            "Iter : 6000 at epoch:  5 /  10  Train Loss :  0.40416608023876327\n",
            "Iter : 7000 at epoch:  5 /  10  Train Loss :  0.3746691923572216\n",
            "Iter : 8000 at epoch:  5 /  10  Train Loss :  0.39296527311229146\n",
            "Iter : 9000 at epoch:  5 /  10  Train Loss :  0.416562045305036\n",
            "Iter : 10000 at epoch:  5 /  10  Train Loss :  0.3898539644582197\n",
            "Iter : 11000 at epoch:  5 /  10  Train Loss :  0.3797958785726223\n",
            "Iter : 12000 at epoch:  5 /  10  Train Loss :  0.3798848861285951\n",
            "Iter : 13000 at epoch:  5 /  10  Train Loss :  0.37927970395749433\n",
            "Iter : 14000 at epoch:  5 /  10  Train Loss :  0.3709107344346121\n",
            "Iter : 15000 at epoch:  5 /  10  Train Loss :  0.40404832700733095\n",
            "Iter : 16000 at epoch:  5 /  10  Train Loss :  0.39040407427004536\n",
            "Iter : 17000 at epoch:  5 /  10  Train Loss :  0.4139655648809858\n",
            "Iter : 18000 at epoch:  5 /  10  Train Loss :  0.39333613886591046\n",
            "Iter : 19000 at epoch:  5 /  10  Train Loss :  0.3929655999969691\n",
            "Iter : 20000 at epoch:  5 /  10  Train Loss :  0.3987849711915478\n",
            "Iter : 21000 at epoch:  5 /  10  Train Loss :  0.3795007161295507\n",
            "Iter : 22000 at epoch:  5 /  10  Train Loss :  0.3707851727413945\n",
            "Iter : 23000 at epoch:  5 /  10  Train Loss :  0.36709022044343875\n",
            "Iter : 24000 at epoch:  5 /  10  Train Loss :  0.4133722466113977\n",
            "Iter:  25000 at epoch:  5 / 10  train loss : 0.4175577509033028 Train acc:  82.92291502236253  val loss:  tensor(0.3823)  val acc:  82.96148179330667\n",
            "Iter : 26000 at epoch:  5 /  10  Train Loss :  0.38962376467650756\n",
            "Iter : 27000 at epoch:  5 /  10  Train Loss :  0.3476943872901611\n",
            "Iter : 28000 at epoch:  5 /  10  Train Loss :  0.3877226867978461\n",
            "Iter : 29000 at epoch:  5 /  10  Train Loss :  0.39264047891367226\n",
            "Iter : 30000 at epoch:  5 /  10  Train Loss :  0.3850721437509637\n",
            "Iter : 31000 at epoch:  5 /  10  Train Loss :  0.3841292882533744\n",
            "Iter : 32000 at epoch:  5 /  10  Train Loss :  0.3962922963430174\n",
            "Iter : 33000 at epoch:  5 /  10  Train Loss :  0.3865314935790375\n",
            "Iter : 34000 at epoch:  5 /  10  Train Loss :  0.3626045445110649\n",
            "Iter : 35000 at epoch:  5 /  10  Train Loss :  0.3809672332690097\n",
            "Iter : 36000 at epoch:  5 /  10  Train Loss :  0.3749423719663173\n",
            "Iter : 37000 at epoch:  5 /  10  Train Loss :  0.3889282472091727\n",
            "Iter : 38000 at epoch:  5 /  10  Train Loss :  0.3639796467428096\n",
            "Iter : 39000 at epoch:  5 /  10  Train Loss :  0.3635287987741176\n",
            "Iter : 40000 at epoch:  5 /  10  Train Loss :  0.36084594375290907\n",
            "Iter : 41000 at epoch:  5 /  10  Train Loss :  0.3520989623293281\n",
            "Iter : 42000 at epoch:  5 /  10  Train Loss :  0.3759433621203061\n",
            "Iter : 43000 at epoch:  5 /  10  Train Loss :  0.38695323855988684\n",
            "Iter : 44000 at epoch:  5 /  10  Train Loss :  0.3934239982748404\n",
            "Iter : 45000 at epoch:  5 /  10  Train Loss :  0.37814466519420964\n",
            "Iter : 46000 at epoch:  5 /  10  Train Loss :  0.40566092729754744\n",
            "Iter : 47000 at epoch:  5 /  10  Train Loss :  0.37767997693968935\n",
            "Iter : 48000 at epoch:  5 /  10  Train Loss :  0.384276487155119\n",
            "Iter : 49000 at epoch:  5 /  10  Train Loss :  0.37365146108483893\n",
            "Iter:  50000 at epoch:  5 / 10  train loss : 0.3456549244998023 Train acc:  82.79531702183635  val loss:  tensor(0.3806)  val acc:  82.78257209008629\n",
            "Iter : 51000 at epoch:  5 /  10  Train Loss :  0.40896099753142334\n",
            "Iter : 52000 at epoch:  5 /  10  Train Loss :  0.40215301089780403\n",
            "Iter : 53000 at epoch:  5 /  10  Train Loss :  0.3784348856911529\n",
            "Iter : 54000 at epoch:  5 /  10  Train Loss :  0.38234045886294915\n",
            "Iter : 55000 at epoch:  5 /  10  Train Loss :  0.4190676328309346\n",
            "Iter : 56000 at epoch:  5 /  10  Train Loss :  0.3837090561420191\n",
            "Iter : 57000 at epoch:  5 /  10  Train Loss :  0.3760162343243137\n",
            "Iter : 58000 at epoch:  5 /  10  Train Loss :  0.36720924110617487\n",
            "Iter : 59000 at epoch:  5 /  10  Train Loss :  0.39093426358001304\n",
            "Iter : 60000 at epoch:  5 /  10  Train Loss :  0.40917912139184776\n",
            "Iter : 61000 at epoch:  5 /  10  Train Loss :  0.3622564000685234\n",
            "Iter : 62000 at epoch:  5 /  10  Train Loss :  0.39127198210265485\n",
            "Iter : 63000 at epoch:  5 /  10  Train Loss :  0.38552879164135084\n",
            "Iter : 64000 at epoch:  5 /  10  Train Loss :  0.3860909239759203\n",
            "Iter : 65000 at epoch:  5 /  10  Train Loss :  0.40214033496426416\n",
            "Iter : 66000 at epoch:  5 /  10  Train Loss :  0.4035360380075872\n",
            "Iter : 67000 at epoch:  5 /  10  Train Loss :  0.3685996131468564\n",
            "Iter : 68000 at epoch:  5 /  10  Train Loss :  0.3602748919799924\n",
            "Iter : 69000 at epoch:  5 /  10  Train Loss :  0.3620548560179304\n",
            "Iter : 70000 at epoch:  5 /  10  Train Loss :  0.38394446863769555\n",
            "Iter : 71000 at epoch:  5 /  10  Train Loss :  0.4007291281330399\n",
            "Iter : 72000 at epoch:  5 /  10  Train Loss :  0.3830939060344826\n",
            "Iter : 73000 at epoch:  5 /  10  Train Loss :  0.3829029196877964\n",
            "Iter : 74000 at epoch:  5 /  10  Train Loss :  0.39451082042744384\n",
            "Iter:  75000 at epoch:  5 / 10  train loss : 0.4037365180333145 Train acc:  82.86766640357801  val loss:  tensor(0.3802)  val acc:  82.91938539254893\n",
            "Iter : 76000 at epoch:  5 /  10  Train Loss :  0.3932489275042899\n",
            "Iter : 1000 at epoch:  6 /  10  Train Loss :  0.35519970703078435\n",
            "Iter : 2000 at epoch:  6 /  10  Train Loss :  0.3850845740409568\n",
            "Iter : 3000 at epoch:  6 /  10  Train Loss :  0.3799564800285734\n",
            "Iter : 4000 at epoch:  6 /  10  Train Loss :  0.3667708556826692\n",
            "Iter : 5000 at epoch:  6 /  10  Train Loss :  0.3731504618264735\n",
            "Iter : 6000 at epoch:  6 /  10  Train Loss :  0.41326418980839663\n",
            "Iter : 7000 at epoch:  6 /  10  Train Loss :  0.36558293799334207\n",
            "Iter : 8000 at epoch:  6 /  10  Train Loss :  0.3763304829709232\n",
            "Iter : 9000 at epoch:  6 /  10  Train Loss :  0.420156225934159\n",
            "Iter : 10000 at epoch:  6 /  10  Train Loss :  0.3879503939230926\n",
            "Iter : 11000 at epoch:  6 /  10  Train Loss :  0.36319096440123394\n",
            "Iter : 12000 at epoch:  6 /  10  Train Loss :  0.39298469641478734\n",
            "Iter : 13000 at epoch:  6 /  10  Train Loss :  0.40764894358813764\n",
            "Iter : 14000 at epoch:  6 /  10  Train Loss :  0.38950401658471673\n",
            "Iter : 15000 at epoch:  6 /  10  Train Loss :  0.3638231990542263\n",
            "Iter : 16000 at epoch:  6 /  10  Train Loss :  0.3823224436719902\n",
            "Iter : 17000 at epoch:  6 /  10  Train Loss :  0.39387840325711293\n",
            "Iter : 18000 at epoch:  6 /  10  Train Loss :  0.3998129042969085\n",
            "Iter : 19000 at epoch:  6 /  10  Train Loss :  0.3962379906794522\n",
            "Iter : 20000 at epoch:  6 /  10  Train Loss :  0.3962033074297942\n",
            "Iter : 21000 at epoch:  6 /  10  Train Loss :  0.36952606682572514\n",
            "Iter : 22000 at epoch:  6 /  10  Train Loss :  0.39114106011902916\n",
            "Iter : 23000 at epoch:  6 /  10  Train Loss :  0.38002331181499177\n",
            "Iter : 24000 at epoch:  6 /  10  Train Loss :  0.38276205269619823\n",
            "Iter:  25000 at epoch:  6 / 10  train loss : 0.3910826690823305 Train acc:  83.07156011575901  val loss:  tensor(0.3803)  val acc:  83.08777099557987\n",
            "Iter : 26000 at epoch:  6 /  10  Train Loss :  0.37144222122617065\n",
            "Iter : 27000 at epoch:  6 /  10  Train Loss :  0.41057995303161443\n",
            "Iter : 28000 at epoch:  6 /  10  Train Loss :  0.3882667538910173\n",
            "Iter : 29000 at epoch:  6 /  10  Train Loss :  0.39299879353120926\n",
            "Iter : 30000 at epoch:  6 /  10  Train Loss :  0.36385995224840006\n",
            "Iter : 31000 at epoch:  6 /  10  Train Loss :  0.37999305527750404\n",
            "Iter : 32000 at epoch:  6 /  10  Train Loss :  0.3686752545540221\n",
            "Iter : 33000 at epoch:  6 /  10  Train Loss :  0.3940147549661342\n",
            "Iter : 34000 at epoch:  6 /  10  Train Loss :  0.38682782675535415\n",
            "Iter : 35000 at epoch:  6 /  10  Train Loss :  0.3785791216879152\n",
            "Iter : 36000 at epoch:  6 /  10  Train Loss :  0.39910885227448306\n",
            "Iter : 37000 at epoch:  6 /  10  Train Loss :  0.351476219211705\n",
            "Iter : 38000 at epoch:  6 /  10  Train Loss :  0.35570154066965914\n",
            "Iter : 39000 at epoch:  6 /  10  Train Loss :  0.38555561669543387\n",
            "Iter : 40000 at epoch:  6 /  10  Train Loss :  0.38167152653308584\n",
            "Iter : 41000 at epoch:  6 /  10  Train Loss :  0.3780357096560765\n",
            "Iter : 42000 at epoch:  6 /  10  Train Loss :  0.3818094681138173\n",
            "Iter : 43000 at epoch:  6 /  10  Train Loss :  0.39457460784679277\n",
            "Iter : 44000 at epoch:  6 /  10  Train Loss :  0.38019724787399173\n",
            "Iter : 45000 at epoch:  6 /  10  Train Loss :  0.3964067815891467\n",
            "Iter : 46000 at epoch:  6 /  10  Train Loss :  0.37700563176139257\n",
            "Iter : 47000 at epoch:  6 /  10  Train Loss :  0.37895474522793665\n",
            "Iter : 48000 at epoch:  6 /  10  Train Loss :  0.3763716499293223\n",
            "Iter : 49000 at epoch:  6 /  10  Train Loss :  0.36750738975801506\n",
            "Iter:  50000 at epoch:  6 / 10  train loss : 0.3663368972921744 Train acc:  82.99394896079978  val loss:  tensor(0.3790)  val acc:  83.0035781940644\n",
            "Iter : 51000 at epoch:  6 /  10  Train Loss :  0.37205389464157634\n",
            "Iter : 52000 at epoch:  6 /  10  Train Loss :  0.3664792601331137\n",
            "Iter : 53000 at epoch:  6 /  10  Train Loss :  0.3948164618038572\n",
            "Iter : 54000 at epoch:  6 /  10  Train Loss :  0.38343674164637925\n",
            "Iter : 55000 at epoch:  6 /  10  Train Loss :  0.3783102221079171\n",
            "Iter : 56000 at epoch:  6 /  10  Train Loss :  0.3759244461704511\n",
            "Iter : 57000 at epoch:  6 /  10  Train Loss :  0.3636339242937975\n",
            "Iter : 58000 at epoch:  6 /  10  Train Loss :  0.3861483645318076\n",
            "Iter : 59000 at epoch:  6 /  10  Train Loss :  0.4049984474389348\n",
            "Iter : 60000 at epoch:  6 /  10  Train Loss :  0.41413226280687376\n",
            "Iter : 61000 at epoch:  6 /  10  Train Loss :  0.37700555638899097\n",
            "Iter : 62000 at epoch:  6 /  10  Train Loss :  0.40621764057152904\n",
            "Iter : 63000 at epoch:  6 /  10  Train Loss :  0.4053103483784944\n",
            "Iter : 64000 at epoch:  6 /  10  Train Loss :  0.3895287864189595\n",
            "Iter : 65000 at epoch:  6 /  10  Train Loss :  0.3238272841540165\n",
            "Iter : 66000 at epoch:  6 /  10  Train Loss :  0.41877218054700643\n",
            "Iter : 67000 at epoch:  6 /  10  Train Loss :  0.38514138281391935\n",
            "Iter : 68000 at epoch:  6 /  10  Train Loss :  0.3636830695234239\n",
            "Iter : 69000 at epoch:  6 /  10  Train Loss :  0.3951184548435267\n",
            "Iter : 70000 at epoch:  6 /  10  Train Loss :  0.3594036249439232\n",
            "Iter : 71000 at epoch:  6 /  10  Train Loss :  0.3560461998360697\n",
            "Iter : 72000 at epoch:  6 /  10  Train Loss :  0.3774297648430802\n",
            "Iter : 73000 at epoch:  6 /  10  Train Loss :  0.41874553402792664\n",
            "Iter : 74000 at epoch:  6 /  10  Train Loss :  0.38682687703403645\n",
            "Iter:  75000 at epoch:  6 / 10  train loss : 0.36164152305107566 Train acc:  83.12417784793476  val loss:  tensor(0.3771)  val acc:  83.27720479898969\n",
            "Iter : 76000 at epoch:  6 /  10  Train Loss :  0.3614129261735361\n",
            "Iter : 1000 at epoch:  7 /  10  Train Loss :  0.38820865665515886\n",
            "Iter : 2000 at epoch:  7 /  10  Train Loss :  0.39019143997924405\n",
            "Iter : 3000 at epoch:  7 /  10  Train Loss :  0.37274495707592\n",
            "Iter : 4000 at epoch:  7 /  10  Train Loss :  0.40437002163310537\n",
            "Iter : 5000 at epoch:  7 /  10  Train Loss :  0.3829531598759349\n",
            "Iter : 6000 at epoch:  7 /  10  Train Loss :  0.39155678189476023\n",
            "Iter : 7000 at epoch:  7 /  10  Train Loss :  0.33353182816971094\n",
            "Iter : 8000 at epoch:  7 /  10  Train Loss :  0.36755754393036477\n",
            "Iter : 9000 at epoch:  7 /  10  Train Loss :  0.3949234603350051\n",
            "Iter : 10000 at epoch:  7 /  10  Train Loss :  0.376938436238328\n",
            "Iter : 11000 at epoch:  7 /  10  Train Loss :  0.39139076875918544\n",
            "Iter : 12000 at epoch:  7 /  10  Train Loss :  0.37512269797292536\n",
            "Iter : 13000 at epoch:  7 /  10  Train Loss :  0.3698385525222402\n",
            "Iter : 14000 at epoch:  7 /  10  Train Loss :  0.367770529237343\n",
            "Iter : 15000 at epoch:  7 /  10  Train Loss :  0.3655415696497075\n",
            "Iter : 16000 at epoch:  7 /  10  Train Loss :  0.36082360573392364\n",
            "Iter : 17000 at epoch:  7 /  10  Train Loss :  0.3996719213437755\n",
            "Iter : 18000 at epoch:  7 /  10  Train Loss :  0.3791979493263643\n",
            "Iter : 19000 at epoch:  7 /  10  Train Loss :  0.3713234887998551\n",
            "Iter : 20000 at epoch:  7 /  10  Train Loss :  0.3759154118199367\n",
            "Iter : 21000 at epoch:  7 /  10  Train Loss :  0.3762841159431264\n",
            "Iter : 22000 at epoch:  7 /  10  Train Loss :  0.36666493006167\n",
            "Iter : 23000 at epoch:  7 /  10  Train Loss :  0.39733407744718713\n",
            "Iter : 24000 at epoch:  7 /  10  Train Loss :  0.3761691023821477\n",
            "Iter:  25000 at epoch:  7 / 10  train loss : 0.3400825038512703 Train acc:  82.7847934754012  val loss:  tensor(0.3796)  val acc:  82.86676489160176\n",
            "Iter : 26000 at epoch:  7 /  10  Train Loss :  0.4034142949602101\n",
            "Iter : 27000 at epoch:  7 /  10  Train Loss :  0.3684175007134909\n",
            "Iter : 28000 at epoch:  7 /  10  Train Loss :  0.4013282842137851\n",
            "Iter : 29000 at epoch:  7 /  10  Train Loss :  0.37387467462639323\n",
            "Iter : 30000 at epoch:  7 /  10  Train Loss :  0.3848291872609407\n",
            "Iter : 31000 at epoch:  7 /  10  Train Loss :  0.39585967498272656\n",
            "Iter : 32000 at epoch:  7 /  10  Train Loss :  0.39350744026061146\n",
            "Iter : 33000 at epoch:  7 /  10  Train Loss :  0.39765154269617053\n",
            "Iter : 34000 at epoch:  7 /  10  Train Loss :  0.40194544351054357\n",
            "Iter : 35000 at epoch:  7 /  10  Train Loss :  0.3588185275392607\n",
            "Iter : 36000 at epoch:  7 /  10  Train Loss :  0.40061280923197046\n",
            "Iter : 37000 at epoch:  7 /  10  Train Loss :  0.3753998700059019\n",
            "Iter : 38000 at epoch:  7 /  10  Train Loss :  0.384759410380153\n",
            "Iter : 39000 at epoch:  7 /  10  Train Loss :  0.3965861728902673\n",
            "Iter : 40000 at epoch:  7 /  10  Train Loss :  0.40420161812915467\n",
            "Iter : 41000 at epoch:  7 /  10  Train Loss :  0.3596198502718471\n",
            "Iter : 42000 at epoch:  7 /  10  Train Loss :  0.36726119886059316\n",
            "Iter : 43000 at epoch:  7 /  10  Train Loss :  0.36339358300319874\n",
            "Iter : 44000 at epoch:  7 /  10  Train Loss :  0.39774719885829835\n",
            "Iter : 45000 at epoch:  7 /  10  Train Loss :  0.3704582873119507\n",
            "Iter : 46000 at epoch:  7 /  10  Train Loss :  0.3927477275519632\n",
            "Iter : 47000 at epoch:  7 /  10  Train Loss :  0.39543181039602493\n",
            "Iter : 48000 at epoch:  7 /  10  Train Loss :  0.38450239466317\n",
            "Iter : 49000 at epoch:  7 /  10  Train Loss :  0.3707432279516943\n",
            "Iter:  50000 at epoch:  7 / 10  train loss : 0.38691385762463326 Train acc:  83.13996316758747  val loss:  tensor(0.3766)  val acc:  83.11934329614819\n",
            "Iter : 51000 at epoch:  7 /  10  Train Loss :  0.3689534702636302\n",
            "Iter : 52000 at epoch:  7 /  10  Train Loss :  0.3790651982659474\n",
            "Iter : 53000 at epoch:  7 /  10  Train Loss :  0.3817941008314956\n",
            "Iter : 54000 at epoch:  7 /  10  Train Loss :  0.38317968194698915\n",
            "Iter : 55000 at epoch:  7 /  10  Train Loss :  0.3945692275762558\n",
            "Iter : 56000 at epoch:  7 /  10  Train Loss :  0.39242603876348586\n",
            "Iter : 57000 at epoch:  7 /  10  Train Loss :  0.3988445566999726\n",
            "Iter : 58000 at epoch:  7 /  10  Train Loss :  0.38999914957210424\n",
            "Iter : 59000 at epoch:  7 /  10  Train Loss :  0.38942841083719393\n",
            "Iter : 60000 at epoch:  7 /  10  Train Loss :  0.40172288168710657\n",
            "Iter : 61000 at epoch:  7 /  10  Train Loss :  0.35912195059238\n",
            "Iter : 62000 at epoch:  7 /  10  Train Loss :  0.38609041287680157\n",
            "Iter : 63000 at epoch:  7 /  10  Train Loss :  0.37741127984644846\n",
            "Iter : 64000 at epoch:  7 /  10  Train Loss :  0.3762231057409663\n",
            "Iter : 65000 at epoch:  7 /  10  Train Loss :  0.3846804760165978\n",
            "Iter : 66000 at epoch:  7 /  10  Train Loss :  0.38627862434391863\n",
            "Iter : 67000 at epoch:  7 /  10  Train Loss :  0.36210160166933203\n",
            "Iter : 68000 at epoch:  7 /  10  Train Loss :  0.38798160377889873\n",
            "Iter : 69000 at epoch:  7 /  10  Train Loss :  0.3787618316404987\n",
            "Iter : 70000 at epoch:  7 /  10  Train Loss :  0.4088191671411041\n",
            "Iter : 71000 at epoch:  7 /  10  Train Loss :  0.3235476062617963\n",
            "Iter : 72000 at epoch:  7 /  10  Train Loss :  0.3625287777981721\n",
            "Iter : 73000 at epoch:  7 /  10  Train Loss :  0.3833487461940385\n",
            "Iter : 74000 at epoch:  7 /  10  Train Loss :  0.3352879657545127\n",
            "Iter:  75000 at epoch:  7 / 10  train loss : 0.3788660881638061 Train acc:  83.21888976585109  val loss:  tensor(0.3759)  val acc:  83.26668069880026\n",
            "Iter : 76000 at epoch:  7 /  10  Train Loss :  0.3836344915672671\n",
            "Iter : 1000 at epoch:  8 /  10  Train Loss :  0.37490492751821874\n",
            "Iter : 2000 at epoch:  8 /  10  Train Loss :  0.3907890002653003\n",
            "Iter : 3000 at epoch:  8 /  10  Train Loss :  0.3709701791387051\n",
            "Iter : 4000 at epoch:  8 /  10  Train Loss :  0.36106212899181994\n",
            "Iter : 5000 at epoch:  8 /  10  Train Loss :  0.3820752320722677\n",
            "Iter : 6000 at epoch:  8 /  10  Train Loss :  0.37719157939380965\n",
            "Iter : 7000 at epoch:  8 /  10  Train Loss :  0.3608275747045409\n",
            "Iter : 8000 at epoch:  8 /  10  Train Loss :  0.3749485245370306\n",
            "Iter : 9000 at epoch:  8 /  10  Train Loss :  0.3748522869462613\n",
            "Iter : 10000 at epoch:  8 /  10  Train Loss :  0.3688670010883361\n",
            "Iter : 11000 at epoch:  8 /  10  Train Loss :  0.38416557368310167\n",
            "Iter : 12000 at epoch:  8 /  10  Train Loss :  0.3604403176610358\n",
            "Iter : 13000 at epoch:  8 /  10  Train Loss :  0.36195478768367323\n",
            "Iter : 14000 at epoch:  8 /  10  Train Loss :  0.3532830686023226\n",
            "Iter : 15000 at epoch:  8 /  10  Train Loss :  0.38369886461785063\n",
            "Iter : 16000 at epoch:  8 /  10  Train Loss :  0.39828025619406254\n",
            "Iter : 17000 at epoch:  8 /  10  Train Loss :  0.37315318766445854\n",
            "Iter : 18000 at epoch:  8 /  10  Train Loss :  0.3731739586556796\n",
            "Iter : 19000 at epoch:  8 /  10  Train Loss :  0.3803271155511029\n",
            "Iter : 20000 at epoch:  8 /  10  Train Loss :  0.38440000589750706\n",
            "Iter : 21000 at epoch:  8 /  10  Train Loss :  0.36855578918056564\n",
            "Iter : 22000 at epoch:  8 /  10  Train Loss :  0.37210161773872097\n",
            "Iter : 23000 at epoch:  8 /  10  Train Loss :  0.34678554737893863\n",
            "Iter : 24000 at epoch:  8 /  10  Train Loss :  0.3494088019762421\n",
            "Iter:  25000 at epoch:  8 / 10  train loss : 0.4004206791818142 Train acc:  82.82294133122863  val loss:  tensor(0.3799)  val acc:  82.9404335929278\n",
            "Iter : 26000 at epoch:  8 /  10  Train Loss :  0.3894355929316953\n",
            "Iter : 27000 at epoch:  8 /  10  Train Loss :  0.4061170413903892\n",
            "Iter : 28000 at epoch:  8 /  10  Train Loss :  0.3608500434793532\n",
            "Iter : 29000 at epoch:  8 /  10  Train Loss :  0.3808714432681445\n",
            "Iter : 30000 at epoch:  8 /  10  Train Loss :  0.3386122521697544\n",
            "Iter : 31000 at epoch:  8 /  10  Train Loss :  0.36256887154816647\n",
            "Iter : 32000 at epoch:  8 /  10  Train Loss :  0.37108018128806725\n",
            "Iter : 33000 at epoch:  8 /  10  Train Loss :  0.3707671585723292\n",
            "Iter : 34000 at epoch:  8 /  10  Train Loss :  0.35596735020540654\n",
            "Iter : 35000 at epoch:  8 /  10  Train Loss :  0.39119213103340006\n",
            "Iter : 36000 at epoch:  8 /  10  Train Loss :  0.38146840261342\n",
            "Iter : 37000 at epoch:  8 /  10  Train Loss :  0.3674394752422813\n",
            "Iter : 38000 at epoch:  8 /  10  Train Loss :  0.3913105338655878\n",
            "Iter : 39000 at epoch:  8 /  10  Train Loss :  0.35893663378059865\n",
            "Iter : 40000 at epoch:  8 /  10  Train Loss :  0.41934534367662857\n",
            "Iter : 41000 at epoch:  8 /  10  Train Loss :  0.3737893610375468\n",
            "Iter : 42000 at epoch:  8 /  10  Train Loss :  0.41211765580810605\n",
            "Iter : 43000 at epoch:  8 /  10  Train Loss :  0.4032360874330625\n",
            "Iter : 44000 at epoch:  8 /  10  Train Loss :  0.3869243076830171\n",
            "Iter : 45000 at epoch:  8 /  10  Train Loss :  0.3869238742340822\n",
            "Iter : 46000 at epoch:  8 /  10  Train Loss :  0.4315455753307324\n",
            "Iter : 47000 at epoch:  8 /  10  Train Loss :  0.3882472962795291\n",
            "Iter : 48000 at epoch:  8 /  10  Train Loss :  0.3529999496759847\n",
            "Iter : 49000 at epoch:  8 /  10  Train Loss :  0.3797063804136124\n",
            "Iter:  50000 at epoch:  8 / 10  train loss : 0.3788240924258716 Train acc:  83.25572217837411  val loss:  tensor(0.3758)  val acc:  83.18248789728479\n",
            "Iter : 51000 at epoch:  8 /  10  Train Loss :  0.3973564689909108\n",
            "Iter : 52000 at epoch:  8 /  10  Train Loss :  0.39169454138586296\n",
            "Iter : 53000 at epoch:  8 /  10  Train Loss :  0.38555317830760033\n",
            "Iter : 54000 at epoch:  8 /  10  Train Loss :  0.3751516476985998\n",
            "Iter : 55000 at epoch:  8 /  10  Train Loss :  0.4009335639476776\n",
            "Iter : 56000 at epoch:  8 /  10  Train Loss :  0.382156948935939\n",
            "Iter : 57000 at epoch:  8 /  10  Train Loss :  0.4148518279429991\n",
            "Iter : 58000 at epoch:  8 /  10  Train Loss :  0.36649719784548507\n",
            "Iter : 59000 at epoch:  8 /  10  Train Loss :  0.38559464698750523\n",
            "Iter : 60000 at epoch:  8 /  10  Train Loss :  0.34964460789831353\n",
            "Iter : 61000 at epoch:  8 /  10  Train Loss :  0.38393754193442875\n",
            "Iter : 62000 at epoch:  8 /  10  Train Loss :  0.3708036091509275\n",
            "Iter : 63000 at epoch:  8 /  10  Train Loss :  0.37982727779401465\n",
            "Iter : 64000 at epoch:  8 /  10  Train Loss :  0.37025744049600323\n",
            "Iter : 65000 at epoch:  8 /  10  Train Loss :  0.384654932775069\n",
            "Iter : 66000 at epoch:  8 /  10  Train Loss :  0.3796664246628061\n",
            "Iter : 67000 at epoch:  8 /  10  Train Loss :  0.378068209847901\n",
            "Iter : 68000 at epoch:  8 /  10  Train Loss :  0.37611774150049315\n",
            "Iter : 69000 at epoch:  8 /  10  Train Loss :  0.37565877759689464\n",
            "Iter : 70000 at epoch:  8 /  10  Train Loss :  0.3744050394848455\n",
            "Iter : 71000 at epoch:  8 /  10  Train Loss :  0.38008445902611127\n",
            "Iter : 72000 at epoch:  8 /  10  Train Loss :  0.41930555127584374\n",
            "Iter : 73000 at epoch:  8 /  10  Train Loss :  0.3772355122792069\n",
            "Iter : 74000 at epoch:  8 /  10  Train Loss :  0.36556171911023555\n",
            "Iter:  75000 at epoch:  8 / 10  train loss : 0.3837864886522293 Train acc:  82.71244409365957  val loss:  tensor(0.3804)  val acc:  82.6878551883814\n",
            "Iter : 76000 at epoch:  8 /  10  Train Loss :  0.37119004869950006\n",
            "Iter : 1000 at epoch:  9 /  10  Train Loss :  0.3626900590718724\n",
            "Iter : 2000 at epoch:  9 /  10  Train Loss :  0.3794566358979791\n",
            "Iter : 3000 at epoch:  9 /  10  Train Loss :  0.40269359828019513\n",
            "Iter : 4000 at epoch:  9 /  10  Train Loss :  0.40418381441570816\n",
            "Iter : 5000 at epoch:  9 /  10  Train Loss :  0.3710371902603656\n",
            "Iter : 6000 at epoch:  9 /  10  Train Loss :  0.3779354501180351\n",
            "Iter : 7000 at epoch:  9 /  10  Train Loss :  0.3530583515341859\n",
            "Iter : 8000 at epoch:  9 /  10  Train Loss :  0.3744215138533618\n",
            "Iter : 9000 at epoch:  9 /  10  Train Loss :  0.36366736988164483\n",
            "Iter : 10000 at epoch:  9 /  10  Train Loss :  0.37507867785100824\n",
            "Iter : 11000 at epoch:  9 /  10  Train Loss :  0.3682356437991839\n",
            "Iter : 12000 at epoch:  9 /  10  Train Loss :  0.40370350929279814\n",
            "Iter : 13000 at epoch:  9 /  10  Train Loss :  0.3790273968607653\n",
            "Iter : 14000 at epoch:  9 /  10  Train Loss :  0.38883369113411753\n",
            "Iter : 15000 at epoch:  9 /  10  Train Loss :  0.3753852521879599\n",
            "Iter : 16000 at epoch:  9 /  10  Train Loss :  0.370363068443723\n",
            "Iter : 17000 at epoch:  9 /  10  Train Loss :  0.35047121640644036\n",
            "Iter : 18000 at epoch:  9 /  10  Train Loss :  0.36977050596289335\n",
            "Iter : 19000 at epoch:  9 /  10  Train Loss :  0.3828541117331479\n",
            "Iter : 20000 at epoch:  9 /  10  Train Loss :  0.3827748213019222\n",
            "Iter : 21000 at epoch:  9 /  10  Train Loss :  0.37072605022275823\n",
            "Iter : 22000 at epoch:  9 /  10  Train Loss :  0.38490796549478545\n",
            "Iter : 23000 at epoch:  9 /  10  Train Loss :  0.36255368794570675\n",
            "Iter : 24000 at epoch:  9 /  10  Train Loss :  0.37256322816084136\n",
            "Iter:  25000 at epoch:  9 / 10  train loss : 0.41701599549129603 Train acc:  83.30570902394106  val loss:  tensor(0.3743)  val acc:  83.54030730372554\n",
            "Iter : 26000 at epoch:  9 /  10  Train Loss :  0.3685509632306639\n",
            "Iter : 27000 at epoch:  9 /  10  Train Loss :  0.3866068908122834\n",
            "Iter : 28000 at epoch:  9 /  10  Train Loss :  0.3658695945420768\n",
            "Iter : 29000 at epoch:  9 /  10  Train Loss :  0.38138335960148834\n",
            "Iter : 30000 at epoch:  9 /  10  Train Loss :  0.3977495548413135\n",
            "Iter : 31000 at epoch:  9 /  10  Train Loss :  0.3881306267969776\n",
            "Iter : 32000 at epoch:  9 /  10  Train Loss :  0.388517913920572\n",
            "Iter : 33000 at epoch:  9 /  10  Train Loss :  0.37937100098328663\n",
            "Iter : 34000 at epoch:  9 /  10  Train Loss :  0.36321607649396176\n",
            "Iter : 35000 at epoch:  9 /  10  Train Loss :  0.37156074118590915\n",
            "Iter : 36000 at epoch:  9 /  10  Train Loss :  0.38108388043986635\n",
            "Iter : 37000 at epoch:  9 /  10  Train Loss :  0.3520618105728645\n",
            "Iter : 38000 at epoch:  9 /  10  Train Loss :  0.38742754912236704\n",
            "Iter : 39000 at epoch:  9 /  10  Train Loss :  0.36427664464269766\n",
            "Iter : 40000 at epoch:  9 /  10  Train Loss :  0.383207715054974\n",
            "Iter : 41000 at epoch:  9 /  10  Train Loss :  0.38675186023069547\n",
            "Iter : 42000 at epoch:  9 /  10  Train Loss :  0.3972073324988596\n",
            "Iter : 43000 at epoch:  9 /  10  Train Loss :  0.3759600636374671\n",
            "Iter : 44000 at epoch:  9 /  10  Train Loss :  0.3642885641225148\n",
            "Iter : 45000 at epoch:  9 /  10  Train Loss :  0.36066518688132054\n",
            "Iter : 46000 at epoch:  9 /  10  Train Loss :  0.3634069041707553\n",
            "Iter : 47000 at epoch:  9 /  10  Train Loss :  0.35643048395682125\n",
            "Iter : 48000 at epoch:  9 /  10  Train Loss :  0.37467215440561996\n",
            "Iter : 49000 at epoch:  9 /  10  Train Loss :  0.3901453170757741\n",
            "Iter:  50000 at epoch:  9 / 10  train loss : 0.4021214430532418 Train acc:  83.27150749802684  val loss:  tensor(0.3744)  val acc:  83.3719217006946\n",
            "Iter : 51000 at epoch:  9 /  10  Train Loss :  0.3710969186858274\n",
            "Iter : 52000 at epoch:  9 /  10  Train Loss :  0.40261468102713116\n",
            "Iter : 53000 at epoch:  9 /  10  Train Loss :  0.36967205931479113\n",
            "Iter : 54000 at epoch:  9 /  10  Train Loss :  0.3501963252599817\n",
            "Iter : 55000 at epoch:  9 /  10  Train Loss :  0.38664622083469297\n",
            "Iter : 56000 at epoch:  9 /  10  Train Loss :  0.36537272814405153\n",
            "Iter : 57000 at epoch:  9 /  10  Train Loss :  0.4120477942079306\n",
            "Iter : 58000 at epoch:  9 /  10  Train Loss :  0.3740904265132267\n",
            "Iter : 59000 at epoch:  9 /  10  Train Loss :  0.38187474848423153\n",
            "Iter : 60000 at epoch:  9 /  10  Train Loss :  0.37214762761397285\n",
            "Iter : 61000 at epoch:  9 /  10  Train Loss :  0.3973300843806937\n",
            "Iter : 62000 at epoch:  9 /  10  Train Loss :  0.37904595999000595\n",
            "Iter : 63000 at epoch:  9 /  10  Train Loss :  0.3932942959060892\n",
            "Iter : 64000 at epoch:  9 /  10  Train Loss :  0.3997179845655337\n",
            "Iter : 65000 at epoch:  9 /  10  Train Loss :  0.38684220143640413\n",
            "Iter : 66000 at epoch:  9 /  10  Train Loss :  0.3470879382719286\n",
            "Iter : 67000 at epoch:  9 /  10  Train Loss :  0.33056007681507615\n",
            "Iter : 68000 at epoch:  9 /  10  Train Loss :  0.3636166185820475\n",
            "Iter : 69000 at epoch:  9 /  10  Train Loss :  0.42618085839459674\n",
            "Iter : 70000 at epoch:  9 /  10  Train Loss :  0.4025162692044396\n",
            "Iter : 71000 at epoch:  9 /  10  Train Loss :  0.3657889525482897\n",
            "Iter : 72000 at epoch:  9 /  10  Train Loss :  0.3500850589242764\n",
            "Iter : 73000 at epoch:  9 /  10  Train Loss :  0.3570782542582601\n",
            "Iter : 74000 at epoch:  9 /  10  Train Loss :  0.3927222085283138\n",
            "Iter:  75000 at epoch:  9 / 10  train loss : 0.34492978159571064 Train acc:  83.23072875559063  val loss:  tensor(0.3745)  val acc:  83.15091559671647\n",
            "Iter : 76000 at epoch:  9 /  10  Train Loss :  0.3952552837177645\n",
            "Iter : 1000 at epoch:  10 /  10  Train Loss :  0.34663339240010826\n",
            "Iter : 2000 at epoch:  10 /  10  Train Loss :  0.35182880486501383\n",
            "Iter : 3000 at epoch:  10 /  10  Train Loss :  0.3344836108428426\n",
            "Iter : 4000 at epoch:  10 /  10  Train Loss :  0.3399630617338698\n",
            "Iter : 5000 at epoch:  10 /  10  Train Loss :  0.4177608923641965\n",
            "Iter : 6000 at epoch:  10 /  10  Train Loss :  0.34164464033930564\n",
            "Iter : 7000 at epoch:  10 /  10  Train Loss :  0.37176457152469083\n",
            "Iter : 8000 at epoch:  10 /  10  Train Loss :  0.35499816470523365\n",
            "Iter : 9000 at epoch:  10 /  10  Train Loss :  0.3909458350527566\n",
            "Iter : 10000 at epoch:  10 /  10  Train Loss :  0.3840653756828979\n",
            "Iter : 11000 at epoch:  10 /  10  Train Loss :  0.37892773874895647\n",
            "Iter : 12000 at epoch:  10 /  10  Train Loss :  0.3383349460558966\n",
            "Iter : 13000 at epoch:  10 /  10  Train Loss :  0.3923037251131609\n",
            "Iter : 14000 at epoch:  10 /  10  Train Loss :  0.3823184615739156\n",
            "Iter : 15000 at epoch:  10 /  10  Train Loss :  0.3506289305626415\n",
            "Iter : 16000 at epoch:  10 /  10  Train Loss :  0.3869149174825288\n",
            "Iter : 17000 at epoch:  10 /  10  Train Loss :  0.37279169270396234\n",
            "Iter : 18000 at epoch:  10 /  10  Train Loss :  0.3702280306209577\n",
            "Iter : 19000 at epoch:  10 /  10  Train Loss :  0.39761331118410453\n",
            "Iter : 20000 at epoch:  10 /  10  Train Loss :  0.37649431540537626\n",
            "Iter : 21000 at epoch:  10 /  10  Train Loss :  0.347224155954551\n",
            "Iter : 22000 at epoch:  10 /  10  Train Loss :  0.37954080997069833\n",
            "Iter : 23000 at epoch:  10 /  10  Train Loss :  0.37848153052735145\n",
            "Iter : 24000 at epoch:  10 /  10  Train Loss :  0.38020672456640753\n",
            "Iter:  25000 at epoch:  10 / 10  train loss : 0.36244362613209524 Train acc:  83.37016574585635  val loss:  tensor(0.3735)  val acc:  83.41401810145233\n",
            "Iter : 26000 at epoch:  10 /  10  Train Loss :  0.3849777792212553\n",
            "Iter : 27000 at epoch:  10 /  10  Train Loss :  0.372677855119342\n",
            "Iter : 28000 at epoch:  10 /  10  Train Loss :  0.40915132856415587\n",
            "Iter : 29000 at epoch:  10 /  10  Train Loss :  0.34058249621582215\n",
            "Iter : 30000 at epoch:  10 /  10  Train Loss :  0.356362743269885\n",
            "Iter : 31000 at epoch:  10 /  10  Train Loss :  0.3780814699255861\n",
            "Iter : 32000 at epoch:  10 /  10  Train Loss :  0.3656303790947422\n",
            "Iter : 33000 at epoch:  10 /  10  Train Loss :  0.3665289507396519\n",
            "Iter : 34000 at epoch:  10 /  10  Train Loss :  0.3998039461694425\n",
            "Iter : 35000 at epoch:  10 /  10  Train Loss :  0.36716842384287157\n",
            "Iter : 36000 at epoch:  10 /  10  Train Loss :  0.362264355574036\n",
            "Iter : 37000 at epoch:  10 /  10  Train Loss :  0.39090562814380975\n",
            "Iter : 38000 at epoch:  10 /  10  Train Loss :  0.3904660075895954\n",
            "Iter : 39000 at epoch:  10 /  10  Train Loss :  0.3444086036221124\n",
            "Iter : 40000 at epoch:  10 /  10  Train Loss :  0.38301475206576285\n",
            "Iter : 41000 at epoch:  10 /  10  Train Loss :  0.3785982513150666\n",
            "Iter : 42000 at epoch:  10 /  10  Train Loss :  0.4073265670444816\n",
            "Iter : 43000 at epoch:  10 /  10  Train Loss :  0.3699942879430018\n",
            "Iter : 44000 at epoch:  10 /  10  Train Loss :  0.3945774606638588\n",
            "Iter : 45000 at epoch:  10 /  10  Train Loss :  0.3874949095407501\n",
            "Iter : 46000 at epoch:  10 /  10  Train Loss :  0.3633053935896605\n",
            "Iter : 47000 at epoch:  10 /  10  Train Loss :  0.40639771603629926\n",
            "Iter : 48000 at epoch:  10 /  10  Train Loss :  0.3858509308444336\n",
            "Iter : 49000 at epoch:  10 /  10  Train Loss :  0.37461013499763796\n",
            "Iter:  50000 at epoch:  10 / 10  train loss : 0.3732055105236359 Train acc:  83.3609576427256  val loss:  tensor(0.3738)  val acc:  83.47716270258893\n",
            "Iter : 51000 at epoch:  10 /  10  Train Loss :  0.3829622502774\n",
            "Iter : 52000 at epoch:  10 /  10  Train Loss :  0.358744240879314\n",
            "Iter : 53000 at epoch:  10 /  10  Train Loss :  0.3852030006244313\n",
            "Iter : 54000 at epoch:  10 /  10  Train Loss :  0.3589671459512319\n",
            "Iter : 55000 at epoch:  10 /  10  Train Loss :  0.3838766851255205\n",
            "Iter : 56000 at epoch:  10 /  10  Train Loss :  0.3976836562117096\n",
            "Iter : 57000 at epoch:  10 /  10  Train Loss :  0.3914913005034905\n",
            "Iter : 58000 at epoch:  10 /  10  Train Loss :  0.393718992221402\n",
            "Iter : 59000 at epoch:  10 /  10  Train Loss :  0.37711870413296855\n",
            "Iter : 60000 at epoch:  10 /  10  Train Loss :  0.3874338946901262\n",
            "Iter : 61000 at epoch:  10 /  10  Train Loss :  0.40711959372088313\n",
            "Iter : 62000 at epoch:  10 /  10  Train Loss :  0.40423455265071245\n",
            "Iter : 63000 at epoch:  10 /  10  Train Loss :  0.3694141242865007\n",
            "Iter : 64000 at epoch:  10 /  10  Train Loss :  0.3803027939137537\n",
            "Iter : 65000 at epoch:  10 /  10  Train Loss :  0.41191906059649774\n",
            "Iter : 66000 at epoch:  10 /  10  Train Loss :  0.3714623870605137\n",
            "Iter : 67000 at epoch:  10 /  10  Train Loss :  0.3785278320047073\n",
            "Iter : 68000 at epoch:  10 /  10  Train Loss :  0.39059250775096005\n",
            "Iter : 69000 at epoch:  10 /  10  Train Loss :  0.3761871827384457\n",
            "Iter : 70000 at epoch:  10 /  10  Train Loss :  0.3785215711405035\n",
            "Iter : 71000 at epoch:  10 /  10  Train Loss :  0.38670337094948626\n",
            "Iter : 72000 at epoch:  10 /  10  Train Loss :  0.38265952314436436\n",
            "Iter : 73000 at epoch:  10 /  10  Train Loss :  0.3709213342033327\n",
            "Iter : 74000 at epoch:  10 /  10  Train Loss :  0.37157504398352464\n",
            "Iter:  75000 at epoch:  10 / 10  train loss : 0.3628408220882993 Train acc:  83.41620626151013  val loss:  tensor(0.3734)  val acc:  83.40349400126289\n",
            "Iter : 76000 at epoch:  10 /  10  Train Loss :  0.3728034874736331\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip2mal9-7LOA",
        "colab_type": "text"
      },
      "source": [
        "# **Visualize Loss and Accuracy **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThVaXPA2Z-B9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "bcf1c518-fc3c-421f-dc38-762cd398365b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "total_step_list=np.arange(len(train_loss_list))\n",
        "plt.plot(total_step_list,train_loss_list)\n",
        "plt.plot(total_step_list,val_loss_list)\n",
        "plt.title(\"LOSS\",fontsize=30)\n",
        "plt.xlabel('step',fontsize=20)\n",
        "plt.ylabel('loss',fontsize=20)\n",
        "plt.legend(['train','val'],loc='upper right')\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f35ffdb0d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZHv5SLF3SsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "fe32242d-66f4-49f2-b5b8-953ea75d106f"
      },
      "source": [
        "\n",
        "total_step_list=np.arange(len(train_acc_list))\n",
        "plt.plot(total_step_list,train_acc_list)\n",
        "plt.plot(total_step_list,val_acc_list)\n",
        "plt.title(\"ACCURACY\",fontsize=30)\n",
        "plt.xlabel('step',fontsize=20)\n",
        "plt.ylabel('accuracy',fontsize=20)\n",
        "plt.legend(['train','val'],loc='lower right')\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f35ffc0cf98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_iHxwtv7ily",
        "colab_type": "text"
      },
      "source": [
        "# **Evaluate test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cl9tIAz4iqX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "236a97a5-54db-431d-cf45-082cbdefe4fb"
      },
      "source": [
        "print(\"Test Accuracy : \",evaluate(X_test,y_test,device)[1],\"%\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy :  83.6788382616016 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aam_Gbey7v7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}